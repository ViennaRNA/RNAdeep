{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spotrna_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViennaRNA/RNAdeep/blob/main/notebooks/spotrna_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "104M6XztHd-E"
      },
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C150beMeSSBE"
      },
      "source": [
        "# Install ViennaRNA Package (needed for preprocessing)\n",
        "# Get an old Miniconda that comes with Python 3.6.0 since Colab uses 3.6.9 in the webinterface\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-4.3.11-Linux-x86_64.sh\n",
        "!bash Miniconda3-4.3.11-Linux-x86_64.sh -b -f -p /usr/local/\n",
        "!rm Miniconda3-4.3.11-Linux-x86_64.sh\n",
        "!conda config --add channels defaults\n",
        "!conda config --add channels bioconda\n",
        "!conda config --add channels conda-forge\n",
        "\n",
        "!conda install -y  viennarna\n",
        "!pip install numpy #not sure why this is not available anymore?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v58O-WcEoak"
      },
      "source": [
        "#check import of RNA package\n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.6/site-packages\") \n",
        "import RNA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUwHg_dvcOML"
      },
      "source": [
        "#copy data\n",
        "!cp -r drive/My\\ Drive/data/interim/10000_length70 .\n",
        "!cp -r /content/drive/My\\ Drive/data/normal_lowspike_25-100 .  #=dataset 4\n",
        "!cp -r /content/drive/My\\ Drive/data/normal_25-100 . #=dataset 3\n",
        "!cp -r /content/drive/My\\ Drive/data/uniform_25-100 . #=dataset 1\n",
        "!cp -r /content/drive/My\\ Drive/data/uniform_plus_25-100 . #=dataset 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKqYMz39P6e"
      },
      "source": [
        "#imports\n",
        "!cp drive/My\\ Drive/models/*py . #copy python files\n",
        "from spotrna import spotrna\n",
        "from metrics import mcc,f1,sensitivity\n",
        "from data_generators_rna import PaddedDataMatrixFromInterimFile,DataMatrixFromInterimFile\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import CSVLogger,ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHHLjCceW522"
      },
      "source": [
        "#Train with nonpadded data\n",
        "#Model Settings\n",
        "model = 1\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "\n",
        "directory = \"10000_length70\"\n",
        "train_generator = DataMatrixFromInterimFile(batch_size,os.path.join(directory,\"train\"))\n",
        "val_generator = DataMatrixFromInterimFile(batch_size,os.path.join(directory,\"val\"))\n",
        "\n",
        "m = spotrna(model,False)\n",
        "#alernatively load model\n",
        "#m = keras.models.load_model([path to saved model],custom_objects={\"mcc\":mcc,\"f1\":f1,\"sensitivity\":sensitivity})\n",
        "csvname = \"spotrna_%i_%i_%s.csv\" % (batch_size,model,directory)\n",
        "csv_logger = CSVLogger(csvname, append=True, separator=';')\n",
        "m.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[\"acc\",mcc,f1,sensitivity],run_eagerly=True)\n",
        "checkpoint_filepath = \"spotrna_%i_%i_%s\" % (batch_size,model,directory)\n",
        "#save model with best mcc\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, monitor='val_mcc', mode='max', save_best_only=True)\n",
        "m.fit(x=train_generator, validation_data = val_generator,epochs=num_epochs,shuffle = True,verbose=1,callbacks=[csv_logger,model_checkpoint])\n",
        "#save model after last epochs \n",
        "m.save(\"spotrna_%i_%i_%s_%i\" % (batch_size,model,directory,epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1lLJ_XNaNJk"
      },
      "source": [
        "#Train with nonpadded data\n",
        "#Model Settings\n",
        "model = 1\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "\n",
        "directory = \"uniform_25-100\"\n",
        "train_generator = PaddedDataMatrixFromInterimFile(batch_size,os.path.join(directory,\"train_30k\"))\n",
        "val_generator = DataMatrixFromInterimFile(batch_size,os.path.join(directory,\"val_5k\"))\n",
        "\n",
        "m = spotrna(model,True)\n",
        "#alernatively load model\n",
        "#m = keras.models.load_model([path to saved model],custom_objects={\"mcc\":mcc,\"f1\":f1,\"sensitivity\":sensitivity})\n",
        "csvname = \"spotrna_%i_%i_%s.csv\" % (batch_size,model,directory)\n",
        "csv_logger = CSVLogger(csvname, append=True, separator=';')\n",
        "m.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[\"acc\",mcc,f1,sensitivity],run_eagerly=True)\n",
        "checkpoint_filepath = \"spotrna_%i_%i_%s\" % (batch_size,model,directory)\n",
        "#save model with best mcc\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, monitor='val_mcc', mode='max', save_best_only=True)\n",
        "m.fit(x=train_generator, validation_data = val_generator,epochs=num_epochs,shuffle = True,verbose=1,callbacks=[csv_logger,model_checkpoint])\n",
        "#save model after last epochs \n",
        "m.save(\"spotrna_%i_%i_%s_%i\" % (batch_size,model,directory,epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spwYM1DyWEoX"
      },
      "source": [
        "#use this to evaluate model\n",
        "#[model].evaluate([generator])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}